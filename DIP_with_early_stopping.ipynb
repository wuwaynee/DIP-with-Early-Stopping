{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KKtRAjUEueMC"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Conv2DTranspose, MaxPooling2D, concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","import time\n","import tensorflow.keras.backend as K"]},{"cell_type":"code","source":["# load + preprocess image\n","def load_image(img_path, target_size=(256, 256)):\n","    img = load_img(img_path, target_size=target_size)\n","    img = img_to_array(img)\n","    img = img / 255.0\n","    return img\n"],"metadata":{"id":"ndo4ji1OukBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# UNet\n","def build_unet(input_shape=(256, 256, 3)):\n","    inputs = Input(input_shape)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n","    u9 = concatenate([u9, c1])\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)\n","    model = Model(inputs, outputs)\n","    return model\n"],"metadata":{"id":"vS-zSSFvukfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DnCNN\n","def build_dncnn(input_shape=(256, 256, 3), depth=17, num_filters=64):\n","    input_img = Input(shape=input_shape)\n","    x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(input_img)\n","    for _ in range(depth - 2):\n","        x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(x)\n","    x = Conv2D(3, (3, 3), padding='same')(x)\n","    model = Model(input_img, x)\n","    return model\n"],"metadata":{"id":"Bf7hQVZj7qgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet\n","def build_resnet(input_shape=(256, 256, 3)):\n","    base_model = tf.keras.applications.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n","    x = base_model.output\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n","    x = tf.keras.layers.Dense(512, activation='relu')(x)\n","    x = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n","    model = Model(inputs=base_model.input, outputs=x)\n","    return model\n"],"metadata":{"id":"cAA7G_LqKeav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PSNR\n","def compute_psnr(original, denoised):\n","    original = np.clip(original, 0., 1.)\n","    denoised = np.clip(denoised, 0., 1.)\n","    return peak_signal_noise_ratio(original, denoised)\n","\n","# SSIM\n","def compute_ssim(original, denoised):\n","    original = np.clip(original, 0., 1.)\n","    denoised = np.clip(denoised, 0., 1.)\n","    return structural_similarity(original, denoised, channel_axis=-1)\n","\n","# generation time\n","def measure_time(model, noisy_img):\n","    start_time = time.time()\n","    denoised_img = model.predict(np.expand_dims(noisy_img, axis=0))\n","    end_time = time.time()\n","    return denoised_img, end_time - start_time\n"],"metadata":{"id":"x7WHeNjpukc8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 定義感知損失函數\n","def compute_perceptual_loss(y_true, y_pred):\n","    return K.mean(K.square(y_true - y_pred))\n"],"metadata":{"id":"9v3g6mlcukau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 定義混合損失函數，可決定要不要用感知損失\n","def custom_loss_function(y_true, y_pred):\n","    mse_loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n","    if use_perceptual_loss:\n","      perceptual_loss = compute_perceptual_loss(y_true, y_pred)\n","      return mse_loss + 0.1 * perceptual_loss  # 感知損失的權重，固定在0.1\n","    else:\n","      return mse_loss\n"],"metadata":{"id":"HrNUbEA5ukYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 生成不同的beta_scheduler，控制每個階段加入的noise_level\n","def generate_beta_scheduler(scheduler_type, num_steps, beta_min=0.0001, beta_max=0.1):\n","    if scheduler_type == 'linear':\n","        return np.linspace(beta_min, beta_max, num_steps)\n","    elif scheduler_type == 'scaled_linear':\n","        return np.linspace(beta_min, beta_max, num_steps) ** 2\n","    else:\n","        raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")\n"],"metadata":{"id":"56faQLN0nMBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 使用DDPM的foward過程生成雜訊圖像\n","def ddpm_forward(x0, step, alphabars):\n","    a_bar = alphabars[step]\n","    noise = np.random.normal(size=x0.shape)\n","    noisy_img = a_bar ** 0.5 * x0 + (1 - a_bar) ** 0.5 * noise\n","    return noisy_img\n"],"metadata":{"id":"IBA-E52ur1Nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 動態調整訓練次數的指數衰減函數, 做early-stopping\n","def calculate_epochs(beta, Emax, k, alpha):\n","    return int(Emax * (1 - alpha * np.exp(-k * beta)))\n"],"metadata":{"id":"XBl-oYbYukTs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_path = '/content/image_0.PNG'\n","input_img = load_image(img_path)\n","\n","\n","scheduler_type = 'linear'  # 'linear' or 'scaled_linear'\n","num_steps = 3\n","beta_min = 0.001    ###\n","beta_max = 0.01    ###\n","beta_scheduler = generate_beta_scheduler(scheduler_type, num_steps, beta_min, beta_max)\n","alphas = 1 - beta_scheduler\n","alpha_bars = np.array([np.prod(alphas[:i+1]) for i in range(len(alphas))])\n","\n","\n","# 生成不同noise level的影像序列\n","noisy_images = [ddpm_forward(input_img, i, alpha_bars) for i in range(num_steps)]"],"metadata":{"id":"YlzQiAvqr8Vz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Emax = 100     # 最大訓練次數\n","k = 0.1       # 衰減係數\n","alpha = 0.5     # 調整參數\n","\n","# 控制是否使用感知損失\n","use_perceptual_loss = True    ###\n"],"metadata":{"id":"UU1tvLsLukQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training\n","results = {}\n","model_architecture = 'unet'  # unet or dncnn or resnet\n","psnr_threshold = 0.05\n","ssim_threshold = 0.0005\n","all_denoised_images = []  # 用來存每個階段的去雜訊圖片\n","\n","for stage, (noisy_img, beta) in enumerate(zip(noisy_images, beta_scheduler)):\n","    if model_architecture == 'unet':\n","        model = build_unet()\n","    elif model_architecture == 'dncnn':\n","        model = build_dncnn()\n","    elif model_architecture == 'resnet':\n","        model = build_resnet()\n","\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss_function)\n","\n","    stage_psnr = []\n","    stage_ssim = []\n","\n","    previous_psnr = 0\n","    previous_ssim = 0\n","\n","    for epoch in range(calculate_epochs(beta, Emax, k, alpha)):\n","        model.fit(np.expand_dims(noisy_img, axis=0), np.expand_dims(input_img, axis=0), epochs=1, batch_size=1, verbose=1)\n","\n","        # 測量生成時間\n","        denoised_img, gen_time = measure_time(model, noisy_img)\n","\n","        # 記錄PSNR + SSIM\n","        psnr_value = compute_psnr(input_img, denoised_img[0])\n","        ssim_value = compute_ssim(input_img, denoised_img[0])\n","        loss_value = model.evaluate(np.expand_dims(noisy_img, axis=0), np.expand_dims(input_img, axis=0), verbose=0)\n","\n","        print(f\"Stage: {stage + 1}, Epoch: {epoch + 1}, PSNR: {psnr_value}, SSIM: {ssim_value}, MSE: {loss_value}\")\n","\n","        stage_psnr.append(psnr_value)\n","        stage_ssim.append(ssim_value)\n","\n","        if abs(psnr_value - previous_psnr) < psnr_threshold and abs(ssim_value - previous_ssim) < ssim_threshold:\n","            print(f\"Early stopping at Stage: {stage + 1}, Epoch: {epoch + 1}\")\n","            break\n","\n","        previous_psnr = psnr_value\n","        previous_ssim = ssim_value\n","\n","\n","    results[f'Stage: {stage + 1}, Noise Level: {alpha_bars[stage]}, Beta: {beta}'] = {\n","        'PSNR': psnr_value,\n","        'SSIM': ssim_value,\n","        'Generation Time': gen_time\n","    }\n","\n","    input_img = denoised_img[0]\n","    all_denoised_images.append(input_img)\n","\n","    plt.figure(figsize=(15, 5))\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.imshow(input_img)\n","    plt.subplot(1, 3, 2)\n","    plt.title('Noisy Image')\n","    plt.imshow(noisy_img)\n","    plt.subplot(1, 3, 3)\n","    plt.title('Denoised Image')\n","    plt.imshow(denoised_img[0])\n","    plt.show()\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n","\n","    ax1.plot(range(len(stage_psnr)), stage_psnr, label='PSNR')\n","    ax1.set_xlabel('Epochs')\n","    ax1.set_ylabel('PSNR Value')\n","    ax1.set_title('PSNR over Epochs')\n","    ax1.legend()\n","\n","    ax2.plot(range(len(stage_ssim)), stage_ssim, label='SSIM')\n","    ax2.set_xlabel('Epochs')\n","    ax2.set_ylabel('SSIM Value')\n","    ax2.set_title('SSIM over Epochs')\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"YCxgum0esXnK","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1718709735590,"user_tz":-480,"elapsed":84105,"user":{"displayName":"ali lin","userId":"13843108901888203763"}},"outputId":"e0c29f51-6420-46d9-8c60-7347e7cee41d"},"execution_count":null,"outputs":[]}]}